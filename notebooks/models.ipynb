{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cezarygolecki/projects/magisterka/.venv/lib/python3.11/site-packages/rotary_embedding_torch/rotary_embedding_torch.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n",
      "/Users/cezarygolecki/projects/magisterka/.venv/lib/python3.11/site-packages/rotary_embedding_torch/rotary_embedding_torch.py:262: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.insert(1, \"/\".join(os.path.abspath('').split(\"/\")[:-1]))\n",
    "\n",
    "import torch\n",
    "\n",
    "from models import ClassifierTransformer, DecoderOnlyTransformer\n",
    "\n",
    "from transformer.blocks.utils import ShiftRight, DownsamplingLayer, UpsamplingLayer\n",
    "\n",
    "from transformer.layers.multi_head_attention.attention_mechanism.attn_params import CosformerParams, VanillaParams, PerformerParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_model(model):\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "    size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "    print('model size: {:.3f}MB'.format(size_all_mb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 200.498MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 30])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size, max_length, d_model = 8, 16, 1024\n",
    "vocab_size = 30\n",
    "num_heads = 4\n",
    "\n",
    "method_params = VanillaParams()\n",
    "\n",
    "model = DecoderOnlyTransformer(\n",
    "    d_model=d_model,\n",
    "    vocab_size=vocab_size,\n",
    "    structure=\"6x1024\",\n",
    "    num_heads=num_heads,\n",
    "    method_params=method_params,\n",
    "    apply_rotary_pos_enc=True,\n",
    "    dropout=0.1,\n",
    "    attn_has_outproj=True,\n",
    "    act_fun=\"relu\",\n",
    "    pos_enc_type=\"learnable\",\n",
    "    device=\"cpu\",\n",
    ")\n",
    "\n",
    "x = torch.randint(low=0,high=10,size=(batch_size, max_length))\n",
    "weight_model(model)\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ShiftRight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5094, 0.1889, 0.6503, 0.2646],\n",
      "         [0.7025, 0.8269, 0.8765, 0.6991],\n",
      "         [0.8861, 0.7245, 0.1752, 0.3057],\n",
      "         [0.7518, 0.5491, 0.4045, 0.6779]],\n",
      "\n",
      "        [[0.1519, 0.6030, 0.0880, 0.7727],\n",
      "         [0.6214, 0.6128, 0.2682, 0.8686],\n",
      "         [0.6315, 0.3781, 0.0280, 0.6445],\n",
      "         [0.2567, 0.3052, 0.6363, 0.6880]]])\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.5094, 0.1889, 0.6503, 0.2646],\n",
      "         [0.7025, 0.8269, 0.8765, 0.6991]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.1519, 0.6030, 0.0880, 0.7727],\n",
      "         [0.6214, 0.6128, 0.2682, 0.8686]]])\n"
     ]
    }
   ],
   "source": [
    "sr = ShiftRight(2)\n",
    "x = torch.rand(2,4,4)\n",
    "print(x)\n",
    "print(sr(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.7694, 0.6985, 0.6660, 0.1967],\n",
      "         [0.0062, 0.5241, 0.8500, 0.3925],\n",
      "         [0.1267, 0.6699, 0.8163, 0.7819],\n",
      "         [0.4394, 0.6064, 0.1130, 0.0887]],\n",
      "\n",
      "        [[0.8162, 0.2403, 0.0268, 0.4737],\n",
      "         [0.9123, 0.3872, 0.7385, 0.2919],\n",
      "         [0.5827, 0.2822, 0.8665, 0.6915],\n",
      "         [0.0313, 0.4579, 0.0186, 0.8751]]])\n",
      "tensor([[[-0.0042, -0.0704, -0.7758,  0.7127],\n",
      "         [-0.3964,  0.3781, -0.5826,  0.5683]],\n",
      "\n",
      "        [[-0.4693, -0.0624, -0.7208,  0.3145],\n",
      "         [-0.1135,  0.0774, -0.7928,  0.7974]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ds = DownsamplingLayer(4, 2)\n",
    "x = torch.rand(2,4,4)\n",
    "print(x)\n",
    "print(ds(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9008, 0.6034, 0.1423, 0.6246],\n",
      "         [0.6567, 0.9595, 0.5829, 0.9248],\n",
      "         [0.2808, 0.6677, 0.4141, 0.9785],\n",
      "         [0.9868, 0.5687, 0.6689, 0.4301]],\n",
      "\n",
      "        [[0.5266, 0.1060, 0.3934, 0.0352],\n",
      "         [0.7165, 0.7234, 0.8946, 0.7398],\n",
      "         [0.1611, 0.4775, 0.7440, 0.9856],\n",
      "         [0.1146, 0.0751, 0.3384, 0.8298]]])\n",
      "tensor([[[-6.3578e-01, -2.6518e-01, -1.8701e-01,  2.2499e-01],\n",
      "         [ 8.4219e-01, -6.6328e-01,  2.7802e-01,  3.6642e-01],\n",
      "         [-6.1478e-01, -2.4426e-01, -6.9666e-02,  2.8947e-01],\n",
      "         [ 7.7288e-01, -9.0025e-01,  1.7178e-01,  4.0270e-01],\n",
      "         [-4.2795e-01, -3.0789e-01, -3.3951e-02,  4.4959e-01],\n",
      "         [ 5.7789e-01, -9.3200e-01,  2.4812e-01,  5.0994e-01],\n",
      "         [-4.9557e-01,  5.7479e-03,  8.9243e-03,  7.7401e-02],\n",
      "         [ 8.4704e-01, -6.5836e-01,  1.6229e-01,  3.6996e-02]],\n",
      "\n",
      "        [[-7.9698e-02,  6.2831e-02, -2.0158e-04,  1.5463e-01],\n",
      "         [ 6.4092e-01, -4.8436e-01,  1.7835e-01, -1.2602e-02],\n",
      "         [-4.6890e-01, -3.6690e-02,  1.0063e-01,  1.9677e-01],\n",
      "         [ 7.3595e-01, -8.6290e-01,  1.3964e-01,  1.3996e-01],\n",
      "         [-2.7359e-01, -1.6781e-01,  1.5923e-01,  4.5433e-01],\n",
      "         [ 4.6524e-01, -1.0014e+00,  2.3253e-01,  3.5704e-01],\n",
      "         [-1.9222e-01, -2.2844e-01,  9.6150e-02,  5.0737e-01],\n",
      "         [ 4.0201e-01, -8.6431e-01,  3.5294e-01,  4.0594e-01]]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "us = UpsamplingLayer(4, 2)\n",
    "x = torch.rand(2,4,4)\n",
    "print(x)\n",
    "print(us(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 0.096MB\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "einsum(): the number of subscripts in the equation (4) does not match the number of dimensions (3) for operand 0 and no ellipsis was given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/cezarygolecki/projects/magisterka/notebooks/models.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cezarygolecki/projects/magisterka/notebooks/models.ipynb#X12sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandint(low\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,high\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m,size\u001b[39m=\u001b[39m(batch_size, max_length))\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cezarygolecki/projects/magisterka/notebooks/models.ipynb#X12sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m weight_model(model)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/cezarygolecki/projects/magisterka/notebooks/models.ipynb#X12sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m model(x)\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m~/projects/magisterka/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/projects/magisterka/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/magisterka/models/classifier.py:112\u001b[0m, in \u001b[0;36mClassifierTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    109\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_enc(x)\n\u001b[1;32m    111\u001b[0m \u001b[39m# Encoder\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x, causal\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    114\u001b[0m \u001b[39m# Pooling\u001b[39;00m\n\u001b[1;32m    115\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/projects/magisterka/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/projects/magisterka/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/magisterka/transformer/blocks/block.py:196\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x, causal, inference)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    193\u001b[0m     \u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor, causal: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, inference: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    194\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m    195\u001b[0m     \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m--> 196\u001b[0m         x \u001b[39m=\u001b[39m layer(x, causal\u001b[39m=\u001b[39;49mcausal, inference\u001b[39m=\u001b[39;49minference)\n\u001b[1;32m    197\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_outproj:\n\u001b[1;32m    198\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_proj(x)\n",
      "File \u001b[0;32m~/projects/magisterka/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/projects/magisterka/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/magisterka/transformer/blocks/block.py:104\u001b[0m, in \u001b[0;36mBlockLayer.forward\u001b[0;34m(self, x, causal, inference)\u001b[0m\n\u001b[1;32m    102\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x)\n\u001b[1;32m    103\u001b[0m \u001b[39m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(query\u001b[39m=\u001b[39;49mx, key\u001b[39m=\u001b[39;49mx, value\u001b[39m=\u001b[39;49mx, causal\u001b[39m=\u001b[39;49mcausal, inference\u001b[39m=\u001b[39;49minference)\n\u001b[1;32m    105\u001b[0m \u001b[39m# Add\u001b[39;00m\n\u001b[1;32m    106\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout1(x) \u001b[39m+\u001b[39m residual\n",
      "File \u001b[0;32m~/projects/magisterka/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/projects/magisterka/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/magisterka/transformer/layers/multi_head_attention/multi_head_attention.py:125\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, query, key, value, causal, inference)\u001b[0m\n\u001b[1;32m    122\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact_fun(key)\n\u001b[1;32m    124\u001b[0m \u001b[39m# Apply Multi-Head Attention mechanism\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m attention_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention_mechanism(\n\u001b[1;32m    126\u001b[0m     query, key, value, causal\u001b[39m=\u001b[39;49mcausal, inference\u001b[39m=\u001b[39;49minference\n\u001b[1;32m    127\u001b[0m )\n\u001b[1;32m    129\u001b[0m \u001b[39m# Output projection with dropout\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_outproj:\n",
      "File \u001b[0;32m~/projects/magisterka/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/projects/magisterka/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/magisterka/transformer/layers/multi_head_attention/attention_mechanism/__init__.py:107\u001b[0m, in \u001b[0;36mAttentionMechanism.forward\u001b[0;34m(self, query, key, value, causal, inference)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[39m# Apply attention mechanism\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention_mechanism(\n\u001b[1;32m    108\u001b[0m     query\u001b[39m=\u001b[39;49mquery, key\u001b[39m=\u001b[39;49mkey, value\u001b[39m=\u001b[39;49mvalue, causal\u001b[39m=\u001b[39;49mcausal, inference\u001b[39m=\u001b[39;49minference\n\u001b[1;32m    109\u001b[0m )\n",
      "File \u001b[0;32m~/projects/magisterka/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/projects/magisterka/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/magisterka/transformer/layers/multi_head_attention/attention_mechanism/cosformer/__init__.py:190\u001b[0m, in \u001b[0;36mCosformer.forward\u001b[0;34m(self, query, key, value, causal, inference, start_pos)\u001b[0m\n\u001b[1;32m    179\u001b[0m     out \u001b[39m=\u001b[39m attention_causal(\n\u001b[1;32m    180\u001b[0m         query\u001b[39m=\u001b[39mq_,\n\u001b[1;32m    181\u001b[0m         key\u001b[39m=\u001b[39mk_,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m         device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice,\n\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    189\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m causal \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m inference:\n\u001b[0;32m--> 190\u001b[0m     out \u001b[39m=\u001b[39m attention_noncausal(q_, k_, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps)\n\u001b[1;32m    191\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minference(q_, k_, value)\n",
      "File \u001b[0;32m~/projects/magisterka/transformer/layers/multi_head_attention/attention_mechanism/cosformer/attention_noncausal.py:25\u001b[0m, in \u001b[0;36mattention_noncausal\u001b[0;34m(query, key, value, eps)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mattention_noncausal\u001b[39m(\n\u001b[1;32m      5\u001b[0m     query: torch\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m      6\u001b[0m     key: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[39m# # (N * h, L, d) -> (L, N * h, d) -> (L, N, E)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[39m# attn_output = attn_output.transpose(0, 1).contiguous().view(tgt_len, bsz, -1)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m    Non causal attention mechanism for the cosformer model.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39m    :return: attention mechanism output, tensor of shape [B, L, Nh, Dh]\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     kv_ \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49meinsum(\n\u001b[1;32m     26\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mbnld,bnlm->bndm\u001b[39;49m\u001b[39m\"\u001b[39;49m, key, value\n\u001b[1;32m     27\u001b[0m     )  \u001b[39m# [B, Nh, L, 2 * Dh], [B, Nh, L, Dh] -> [B, Nh, 2 * Dh, Dh]\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     z_ \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m/\u001b[39m torch\u001b[39m.\u001b[39mclamp_min(\n\u001b[1;32m     29\u001b[0m         torch\u001b[39m.\u001b[39meinsum(\u001b[39m\"\u001b[39m\u001b[39mbnld,bnd->bnl\u001b[39m\u001b[39m\"\u001b[39m, query, torch\u001b[39m.\u001b[39msum(key, axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)), eps\n\u001b[1;32m     30\u001b[0m     )  \u001b[39m# [B, Nh, L, 2 * Dh], [B, Nh, L] -> [B, Nh, L]\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     attn_output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39meinsum(\n\u001b[1;32m     32\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbnld,bndm,bnl->bnlm\u001b[39m\u001b[39m\"\u001b[39m, query, kv_, z_\n\u001b[1;32m     33\u001b[0m     )  \u001b[39m# [B, Nh, L, 2 * Dh], [B, Nh, 2 * Dh, Dh], [B, Nh, L] -> [B, Nh, L, Dh]\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/magisterka/.venv/lib/python3.11/site-packages/torch/functional.py:386\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[39mreturn\u001b[39;00m einsum(equation, \u001b[39m*\u001b[39m_operands)\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(operands) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m opt_einsum\u001b[39m.\u001b[39menabled:\n\u001b[1;32m    384\u001b[0m     \u001b[39m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[1;32m    385\u001b[0m     \u001b[39m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[0;32m--> 386\u001b[0m     \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39;49meinsum(equation, operands)  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    388\u001b[0m path \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[39mif\u001b[39;00m opt_einsum\u001b[39m.\u001b[39mis_available():\n",
      "\u001b[0;31mRuntimeError\u001b[0m: einsum(): the number of subscripts in the equation (4) does not match the number of dimensions (3) for operand 0 and no ellipsis was given"
     ]
    }
   ],
   "source": [
    "batch_size, max_length, d_model = 8, 16, 27\n",
    "vocab_size = 100\n",
    "num_heads = 9\n",
    "\n",
    "device = \"mps\"\n",
    "\n",
    "model = ClassifierTransformer(\n",
    "    d_model=d_model,\n",
    "    vocab_size=vocab_size,\n",
    "    structure=\"3x16\",\n",
    "    num_classes=2,\n",
    "    num_heads=num_heads,\n",
    "    method_params=CosformerParams(),\n",
    "    apply_rotary_pos_enc=True,\n",
    "    dropout=0.1,\n",
    "    attn_has_outproj=True,\n",
    "    act_fun=\"gelu\",\n",
    "    pos_enc_type=\"learnable\",\n",
    "    norm_before=True,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "x = torch.randint(low=0,high=100,size=(batch_size, max_length)).to(device)\n",
    "\n",
    "weight_model(model)\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size, max_length, d_model = 8, 16, 64\n",
    "vocab_size = 100\n",
    "num_heads = 4\n",
    "\n",
    "model = ClassifierTransformer(\n",
    "    d_model=d_model,\n",
    "    vocab_size=vocab_size,\n",
    "    structure=\"3x64,3x32\",\n",
    "    num_classes=2,\n",
    "    num_heads=num_heads,\n",
    "    method_params=CosformerParams(),\n",
    "    apply_rotary_pos_enc=True,\n",
    "    dropout=0.1,\n",
    "    attn_has_outproj=True,\n",
    "    act_fun=\"gelu\",\n",
    "    pos_enc_type=\"learnable\",\n",
    "    norm_before=True,\n",
    "    device=\"cpu\",\n",
    ")\n",
    "\n",
    "x = torch.randint(low=0,high=100,size=(batch_size, max_length))\n",
    "\n",
    "model(x).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
