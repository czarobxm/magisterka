{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cezarygolecki/projects/magisterka/.venv/lib/python3.11/site-packages/rotary_embedding_torch/rotary_embedding_torch.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n",
      "/Users/cezarygolecki/projects/magisterka/.venv/lib/python3.11/site-packages/rotary_embedding_torch/rotary_embedding_torch.py:262: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.insert(1, \"/\".join(os.path.abspath('').split(\"/\")[:-1]))\n",
    "\n",
    "import torch\n",
    "from transformer.layers.multi_head_attention.attention_mechanism import AttentionMechanism\n",
    "from transformer.layers.multi_head_attention.attention_mechanism.attn_params import CosformerParams, PerformerParams, VanillaParams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5657, 0.9102, 0.4936, 0.4829, 0.8961, 0.7027],\n",
      "         [0.3888, 0.6483, 0.7919, 0.5930, 0.6692, 0.8222],\n",
      "         [0.5063, 0.5966, 0.6915, 0.1719, 0.1601, 0.7999],\n",
      "         [0.3149, 0.1427, 0.8747, 0.5326, 0.1205, 0.7668],\n",
      "         [0.5580, 0.1022, 0.6013, 0.5190, 0.3250, 0.5759]],\n",
      "\n",
      "        [[0.9509, 0.2620, 0.6980, 0.8866, 0.2526, 0.7136],\n",
      "         [0.7622, 0.4612, 0.4851, 0.7294, 0.4967, 0.4696],\n",
      "         [0.7167, 0.5124, 0.4571, 0.0791, 0.8449, 0.8229],\n",
      "         [0.0682, 0.7522, 0.7331, 0.2848, 0.5429, 0.5549],\n",
      "         [0.2151, 0.6011, 0.4759, 0.2385, 0.5742, 0.5680]]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "seq_len = 5\n",
    "embed_dim = 6\n",
    "device = \"cpu\"\n",
    "x = torch.rand((batch_size, seq_len, embed_dim)).to(device)\n",
    "v = torch.rand((batch_size, seq_len, embed_dim)).to(device)\n",
    "\n",
    "attn = AttentionMechanism(embed_dim, 2, VanillaParams(), False, device)\n",
    "print(attn(x,x,x, causal=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2991, 0.9926, 0.3933, 0.3136, 0.1052, 0.3166],\n",
      "         [0.8526, 0.9559, 0.4633, 0.6674, 0.5996, 0.2802],\n",
      "         [1.0752, 1.5707, 0.8684, 0.6495, 0.8557, 0.4554],\n",
      "         [1.7370, 1.3269, 1.2396, 0.9752, 1.4806, 0.9087],\n",
      "         [2.3836, 1.9958, 2.1230, 1.4396, 1.9670, 1.0837]],\n",
      "\n",
      "        [[0.3712, 0.1316, 0.0452, 0.5839, 0.1278, 0.3976],\n",
      "         [1.0730, 0.4279, 0.9435, 0.6794, 0.0643, 0.6653],\n",
      "         [1.7908, 1.0752, 1.8308, 0.9476, 0.2954, 1.0438],\n",
      "         [2.1132, 1.3679, 2.8403, 1.5904, 0.9394, 1.6625],\n",
      "         [1.9424, 1.1334, 1.0542, 1.4976, 0.9985, 1.3352]]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "seq_len = 5\n",
    "embed_dim = 6\n",
    "device = \"cpu\"\n",
    "x = torch.rand((batch_size, seq_len, embed_dim)).to(device)\n",
    "v = torch.rand((batch_size, seq_len, embed_dim)).to(device)\n",
    "\n",
    "attn = AttentionMechanism(embed_dim, 2, CosformerParams(), False, device)\n",
    "print(attn(x,x,x, causal=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2452, 0.3107, 0.0795, 0.3327],\n",
       "         [0.7542, 0.3549, 0.1530, 0.4360],\n",
       "         [0.8820, 0.7193, 0.1883, 0.5667],\n",
       "         [1.7823, 1.2945, 0.6118, 1.0059],\n",
       "         [1.6973, 1.8332, 0.7441, 1.2979]],\n",
       "\n",
       "        [[0.8837, 0.2715, 0.0040, 0.1325],\n",
       "         [1.2079, 0.2971, 0.2609, 0.3057],\n",
       "         [2.0842, 0.4372, 0.4336, 0.7278],\n",
       "         [1.6103, 0.8445, 0.6614, 0.8883],\n",
       "         [1.7393, 1.4167, 0.8956, 1.3014]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "seq_len = 5\n",
    "embed_dim = 4\n",
    "device = \"cpu\"\n",
    "\n",
    "x = torch.rand((batch_size, seq_len, embed_dim)).to(device)\n",
    "v = torch.rand((batch_size,  seq_len, embed_dim)).to(device)\n",
    "\n",
    "attn = AttentionMechanism(embed_dim, 2, PerformerParams(),False, device)\n",
    "attn(x,x,v, causal=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
